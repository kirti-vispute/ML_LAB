# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NeRhzEjt2xFp7Te8nk4pZ3X2patmrIgI
"""

# =====================================================
# HEART DISEASE PREDICTION - KAGGLE FINAL CODE
# Dataset Path:
# /kaggle/input/datasets/kirtivispute/prediction-heart-disease-dataset
# =====================================================

# Install libraries (usually already installed)
!pip install -q lightgbm catboost xgboost

# -------------------------------
# 1. Import Libraries
# -------------------------------
import pandas as pd
import numpy as np

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import log_loss
from sklearn.preprocessing import LabelEncoder

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# -------------------------------
# 2. Load Dataset (DIRECTLY)
# -------------------------------
DATA_PATH = "/kaggle/input/datasets/kirtivispute/prediction-heart-disease-dataset"

train = pd.read_csv(f"{DATA_PATH}/train.csv")
test = pd.read_csv(f"{DATA_PATH}/test.csv")

print("Train Shape:", train.shape)
print("Test Shape:", test.shape)

# -------------------------------
# 3. Detect Target Column
# -------------------------------
print("\nColumns:\n", train.columns)

possible_targets = [
    "target",
    "HeartDisease",
    "Heart Disease",
    "output",
    "label"
]

TARGET = None
for col in possible_targets:
    if col in train.columns:
        TARGET = col
        break

if TARGET is None:
    raise Exception("Target column not found!")

print("\nUsing Target Column:", TARGET)

# -------------------------------
# 4. Prepare Data
# -------------------------------
X = train.drop(columns=[TARGET])
y = train[TARGET]

# Convert Absence/Presence â†’ 0/1
if y.dtype == "object":
    y = y.map({"Absence": 0, "Presence": 1})

print("Target Values:", y.unique())

# Remove ID column
if "id" in X.columns:
    X = X.drop(columns=["id"])

if "id" in test.columns:
    test_ids = test["id"]
    test = test.drop(columns=["id"])
else:
    test_ids = np.arange(len(test))

# -------------------------------
# 5. Encode Categorical Features
# -------------------------------
cat_cols = X.select_dtypes(include="object").columns

for col in cat_cols:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))
    test[col] = le.transform(test[col].astype(str))

# Fill missing values
X = X.fillna(X.median(numeric_only=True))
test = test.fillna(test.median(numeric_only=True))

# -------------------------------
# 6. Stratified KFold
# -------------------------------
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

oof_preds = np.zeros(len(X))
test_preds = np.zeros(len(test))

# -------------------------------
# 7. Models
# -------------------------------
xgb_model = XGBClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric="logloss",
    tree_method="hist",
    random_state=42
)

lgb_model = LGBMClassifier(
    n_estimators=200,
    learning_rate=0.05,
    num_leaves=31,
    random_state=42
)

cat_model = CatBoostClassifier(
    iterations=200,
    learning_rate=0.05,
    depth=6,
    verbose=0,
    random_state=42
)

models = [xgb_model, lgb_model, cat_model]

# -------------------------------
# 8. Training Loop
# -------------------------------
for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
    print(f"\nFold {fold+1}")

    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    val_preds = np.zeros(len(X_val))
    test_fold_preds = np.zeros(len(test))

    for model in models:
        model.fit(X_train, y_train)

        val_pred = model.predict_proba(X_val)[:,1]
        test_pred = model.predict_proba(test)[:,1]

        val_preds += val_pred / len(models)
        test_fold_preds += test_pred / len(models)

    oof_preds[val_idx] = val_preds
    test_preds += test_fold_preds / skf.n_splits

    print("Fold Log Loss:", log_loss(y_val, val_preds))

# -------------------------------
# 9. Final Score
# -------------------------------
print("\nOverall CV Log Loss:", log_loss(y, oof_preds))

# -------------------------------
# 10. Submission File
# -------------------------------
submission = pd.DataFrame({
    "id": test_ids,
    TARGET: test_preds
})

submission.to_csv("submission.csv", index=False)

print("\nsubmission.csv created successfully!")